{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8e1a5c9-d99d-49d1-bb35-05934fac40e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unicode-Based Language Detector with Mixed Language Support\n",
      "Enter a sentence or word:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  আপনি একজন ভালো মানুষ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected Language: Bengali (100%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# unicode_language_detector_abhi.py\n",
    "\n",
    "LANGUAGE_UNICODE_RANGES = {\n",
    "    \"English\": [(0x0000, 0x007F)],\n",
    "    \"Bengali\": [(0x0980, 0x09FF)],\n",
    "    \"Hindi\": [(0x0900, 0x097F)],\n",
    "    \"Arabic/persian\": [(0x0600, 0x06FF)],\n",
    "    \"Russian\": [(0x0400, 0x04FF)],\n",
    "    \"Tamil\": [(0x0B80, 0x0BFF)],\n",
    "    \"Telugu\": [(0x0C00, 0x0C7F)],\n",
    "    \"Gujarati\": [(0x0A80, 0x0AFF)],\n",
    "    \"Punjabi\": [(0x0A00, 0x0A7F)],\n",
    "    \"Kannada\": [(0x0C80, 0x0CFF)],\n",
    "    \"Malayalam\": [(0x0D00, 0x0D7F)],\n",
    "    \"Oriya\": [(0x0B00, 0x0B7F)],\n",
    "    \"Marathi\": [(0x0900, 0x097F)],  # Same as Hindi\n",
    "    \"Urdu\": [(0x0600, 0x06FF)],\n",
    "    \"Chinese\": [(0x4E00, 0x9FFF)],\n",
    "    \"Japanese\": [(0x3040, 0x309F), (0x30A0, 0x30FF), (0x4E00, 0x9FFF)],\n",
    "    \"Korean\": [(0xAC00, 0xD7AF)],\n",
    "    \"Greek\": [(0x0370, 0x03FF)],\n",
    "    \"Hebrew\": [(0x0590, 0x05FF)],\n",
    "    \"Thai\": [(0x0E00, 0x0E7F)],\n",
    "    \"Georgian\": [(0x10A0, 0x10FF)],\n",
    "    \"Basic Latin\":[(0x0000,0x007F)],\n",
    "    \"Greek\":[(0x0370,0x03FF)],\n",
    "    \"Cyrillic\":[(0x0400,0x04FF)],\n",
    "    \"Armenian\":[(0x0530,0x058F)],\n",
    "    \"Hebrew\":[(0x0590,0x05FF)],\n",
    "    \"Arabic\":[(0x0600,0x06FF)],\n",
    "    \"Syriac\":[(0x0700,0x074F)],    \n",
    "    \"Thaana\":[(0x0780,0x07BF)],\n",
    "    \"Devanagari\":[(0x0900,0x097F)],\n",
    "    \"Gurmukhi\":[(0x0A00,0x0A7F)],\n",
    "    \"Sinhala\":[(0x0D80,0x0DFF)],\n",
    "    \"Tibetan\":[(0x0F00,0x0FFF)],\n",
    "    \"Myanmar\":[(0x1000,0x109F)],\n",
    "    \"Hangul Jamo\":[(0x1100,0x11FF)],\n",
    "    \"Ethiopic\":[(0x1200,0x137F)],\n",
    "    \"Cherokee\":[(0x13A0,0x13FF)],\n",
    "    \"Ogham\":[(0x1680,0x169F)],\n",
    "    \"Runic\":[(0x16A0,0x16FF)],\n",
    "    \"Khmer\":[(0x1780,0x17FF)],\n",
    "    \"Mongolian\":[(0x1800,0x18AF)],\n",
    "    \"Katakana\":[(0x30A0,0x30FF)],\n",
    "    \"Bopomofo\":[(0x3100,0x312F)],\n",
    "    \"Kanbun\":[(0x3190,0x319F)],\n",
    "    \"Dingbats\":[(0x2700,0x27BF)],\n",
    "    \"Private Use\":[(0xE000,0xF8FF)],\n",
    "    \"Hangul Syllables\":[(0xAC00,0xD7A3)],\n",
    "    \"High Surrogates\":[(0xD800,0xDB7F)]\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "def detect_language_with_percentage(text):\n",
    "    language_counts = {lang: 0 for lang in LANGUAGE_UNICODE_RANGES}\n",
    "    total_letters = 0\n",
    "\n",
    "    for char in text:\n",
    "        if char.isalpha():\n",
    "            total_letters += 1\n",
    "            code_point = ord(char)\n",
    "            for lang, ranges in LANGUAGE_UNICODE_RANGES.items():\n",
    "                if any(start <= code_point <= end for start, end in ranges):\n",
    "                    language_counts[lang] += 1\n",
    "                    break\n",
    "\n",
    "    if total_letters == 0:\n",
    "        return \"No valid characters found.\" \n",
    "\n",
    "    # Filter languages that have non-zero counts\n",
    "    used_languages = {lang: count for lang, count in language_counts.items() if count > 0}\n",
    "\n",
    "    if len(used_languages) == 0:\n",
    "        return \"Language could not be detected.\"\n",
    "\n",
    "    elif len(used_languages) == 1:\n",
    "        only_lang = list(used_languages.keys())[0]\n",
    "        return f\"Detected Language: {only_lang} (100%)\"\n",
    "\n",
    "    else:\n",
    "        # Mixed language\n",
    "        print(\"\\nDetected a **Mixed Language** Sentence.\")\n",
    "        print(\"Language Usage Breakdown:\")\n",
    "        for lang, count in used_languages.items():\n",
    "            percent = (count / total_letters) * 100\n",
    "            print(f\"  - {lang}: {percent:.2f}%\")\n",
    "        return \"Conclusion: Mixed Language\"\n",
    "\n",
    "# --- Main Program ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Unicode-Based Language Detector with Mixed Language Support\")\n",
    "    print(\"Enter a sentence or word:\")\n",
    "\n",
    "    user_input = input(\"> \").strip()\n",
    "\n",
    "    if user_input:\n",
    "        result = detect_language_with_percentage(user_input)\n",
    "        print(\"\\n\" + str(result))\n",
    "    else:\n",
    "        print(\"No input provided.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242ba6ca-55c5-413b-8ba2-48d14c7111ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
